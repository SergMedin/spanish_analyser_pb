#!/usr/bin/env python3
"""
–û—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –≤–µ–±-—Å–∫—Ä–∞–ø–∏–Ω–≥–∞

–î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ HTML —Å—Ç—Ä–∞–Ω–∏—Ü
"""

import sys
from pathlib import Path

"""CLI –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π web_scraper.

–≠—Ç–æ—Ç —Ñ–∞–π–ª –æ—Å—Ç–∞—ë—Ç—Å—è —Ç–æ—á–∫–æ–π –≤—Ö–æ–¥–∞, –∞ –¥–µ–º–æ-—Å–∫—Ä–∏–ø—Ç—ã –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω—ã –≤ –ø–∞–∫–µ—Ç examples/.
"""

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º –ø–∞–∫–µ—Ç–∞
sys.path.insert(0, str(Path(__file__).parent))

from web_scraper import HTMLDownloader, ScrapingManager


def demo_basic_download():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –±–∞–∑–æ–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü"""
    print("=== –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –±–∞–∑–æ–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ ===\n")
    
    # –°–æ–∑–¥–∞—ë–º –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–ª—è —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Å–∞–π—Ç–∞
    downloader = HTMLDownloader(
        base_url="https://httpbin.org/html",
        save_path="./demo_downloads",
        delay_range=(1, 2)
    )
    
    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–¥–Ω—É —Å—Ç—Ä–∞–Ω–∏—Ü—É
        print("–ó–∞–≥—Ä—É–∂–∞—é —Ç–µ—Å—Ç–æ–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É...")
        if downloader.download_page(filename="test_page.html"):
            print("‚úÖ –°—Ç—Ä–∞–Ω–∏—Ü–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        stats = downloader.get_stats()
        print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏:")
        print(f"   –£—Å–ø–µ—à–Ω—ã—Ö: {stats['successful']}")
        print(f"   –ù–µ—É–¥–∞—á–Ω—ã—Ö: {stats['failed']}")
        print(f"   –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {stats['total_requests']}")
        print(f"   –ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {stats['success_rate_percent']}%")
        
    finally:
        downloader.close()


def demo_scraping_manager():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞"""
    print("\n=== –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –º–µ–Ω–µ–¥–∂–µ—Ä–∞ —Å–∫—Ä–∞–ø–∏–Ω–≥–∞ ===\n")
    
    # –°–æ–∑–¥–∞—ë–º –º–µ–Ω–µ–¥–∂–µ—Ä
    manager = ScrapingManager(
        base_url="https://httpbin.org/html",
        save_path="./demo_scraping"
    )
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Å—Å–∏—é —Å–∫—Ä–∞–ø–∏–Ω–≥–∞
    print("–ó–∞–ø—É—Å–∫–∞—é —Å–µ—Å—Å–∏—é —Å–∫—Ä–∞–ø–∏–Ω–≥–∞...")
    session_result = manager.start_scraping_session(
        session_name="demo_session",
        num_pages=3,
        delay_range=(1, 2)
    )
    
    print(f"‚úÖ –°–µ—Å—Å–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {session_result['status']}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å–≤–æ–¥–∫—É –ø–æ –≤—Å–µ–º —Å–µ—Å—Å–∏—è–º
    print("\nüìã –°–≤–æ–¥–∫–∞ –ø–æ —Å–µ—Å—Å–∏—è–º:")
    sessions_summary = manager.get_all_sessions_summary()
    for session in sessions_summary:
        print(f"   {session['name']}: {session['status']}")
    
    # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
    manager.export_metadata_to_csv("demo_summary.csv")
    print("\nüìÅ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤ CSV")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ–±—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    total_stats = manager.get_total_stats()
    print(f"\nüìä –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   –í—Å–µ–≥–æ —Å–µ—Å—Å–∏–π: {total_stats['total_sessions']}")
    print(f"   –ó–∞–≤–µ—Ä—à—ë–Ω–Ω—ã—Ö: {total_stats['completed_sessions']}")
    print(f"   –ù–µ—É–¥–∞—á–Ω—ã—Ö: {total_stats['failed_sessions']}")
    print(f"   –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {total_stats['total_downloaded_files']}")


def demo_parameter_based_scraping():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–∫—Ä–∞–ø–∏–Ω–≥–∞ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏"""
    print("\n=== –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Å–∫—Ä–∞–ø–∏–Ω–≥–∞ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ ===\n")
    
    manager = ScrapingManager(
        base_url="https://httpbin.org/get",
        save_path="./demo_parameters"
    )
    
    # –°–ø–∏—Å–æ–∫ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    parameters_list = [
        {"param1": "value1", "param2": "value2"},
        {"test": "data", "number": "123"},
        {"language": "spanish", "level": "beginner"}
    ]
    
    print("–ó–∞–ø—É—Å–∫–∞—é —Å–∫—Ä–∞–ø–∏–Ω–≥ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏...")
    session_result = manager.scrape_with_parameters(
        session_name="parameters_demo",
        parameters_list=parameters_list,
        delay_range=(1, 2)
    )
    
    print(f"‚úÖ –°–∫—Ä–∞–ø–∏–Ω–≥ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –∑–∞–≤–µ—Ä—à—ë–Ω: {session_result['status']}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if 'results' in session_result:
        print(f"\nüìÑ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        for result in session_result['results']:
            status_emoji = "‚úÖ" if result['status'] == 'success' else "‚ùå"
            print(f"   {status_emoji} {result['filename']}: {result['status']}")


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("üåê –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –≤–µ–±-—Å–∫—Ä–∞–ø–∏–Ω–≥–∞\n")
    
    try:
        # –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
        demo_basic_download()
        demo_scraping_manager()
        demo_parameter_based_scraping()
        
        print("\nüéâ –í—Å–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∑–∞–≤–µ—Ä—à–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ!")
        print("\nüìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫–∞—Ö:")
        print("   - ./demo_downloads/")
        print("   - ./demo_scraping/")
        print("   - ./demo_parameters/")
        
    except Exception as e:
        print(f"\n‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
