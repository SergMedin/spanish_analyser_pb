#!/usr/bin/env python3
"""
–¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —á–∞—Å—Ç–µ–π —Ä–µ—á–∏
"""

import sys
sys.path.append('src')

import spacy
import yaml
import os

# –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –Ω–∞–ø—Ä—è–º—É—é
def load_config():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∏–∑ config.yaml"""
    config_path = "config.yaml"
    if os.path.exists(config_path):
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f) or {}
    return {}

config_data = load_config()
spacy_model = config_data.get('text_analysis', {}).get('spacy_model', 'es_core_news_md')

def test_spacy_directly():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç spaCy –Ω–∞–ø—Ä—è–º—É—é"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ spaCy –Ω–∞–ø—Ä—è–º—É—é")
    print("=" * 50)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å spaCy
    print(f"–ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å: {spacy_model}")

    try:
        nlp = spacy.load(spacy_model)
        print(f"‚úÖ –ú–æ–¥–µ–ª—å {spacy_model} –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return

    # –£–î–ê–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–¥–∏–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–∑ POSTagger
    from spanish_analyser.components.pos_tagger import POSTagger
    pos_tagger = POSTagger()

    # –¢–µ—Å—Ç–æ–≤—ã–µ —Å–ª–æ–≤–∞ –Ω–∞ –∏—Å–ø–∞–Ω—Å–∫–æ–º
    test_words = [
        "casa",      # —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ (–¥–æ–º)
        "correr",    # –≥–ª–∞–≥–æ–ª (–±–µ–≥–∞—Ç—å)
        "r√°pido",    # –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ (–±—ã—Å—Ç—Ä—ã–π)
        "en",        # –ø—Ä–µ–¥–ª–æ–≥ (–≤)
        "yo",        # –º–µ—Å—Ç–æ–∏–º–µ–Ω–∏–µ (—è)
        "feliz",     # –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ (—Å—á–∞—Å—Ç–ª–∏–≤—ã–π)
        "comer",     # –≥–ª–∞–≥–æ–ª (–µ—Å—Ç—å)
        "mesa",      # —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ (—Å—Ç–æ–ª)
        "con",       # –ø—Ä–µ–¥–ª–æ–≥ (—Å)
        "muy"        # –Ω–∞—Ä–µ—á–∏–µ (–æ—á–µ–Ω—å)
    ]

    print()
    print("üìù –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤:")
    print("-" * 30)

    for word in test_words:
        try:
            doc = nlp(word)
            if doc:
                token = doc[0]
                pos_tag = token.pos_
                pos_name = pos_tagger.get_pos_tag_ru(pos_tag)
                print("12")
            else:
                print("12")
        except Exception as e:
            print("12")

    print()
    print("üìä –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ–∫—Å—Ç–∞:")
    print("-" * 30)

    # –¢–µ—Å—Ç–æ–≤—ã–π —Ç–µ–∫—Å—Ç
    test_text = "La casa es muy grande. Yo corro r√°pido en el parque."
    print(f"–¢–µ–∫—Å—Ç: {test_text}")
    print()

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
    doc = nlp(test_text)

    print("–°–ª–æ–≤–∞ —Å —á–∞—Å—Ç—è–º–∏ —Ä–µ—á–∏:")
    for token in doc:
        if token.is_alpha:
                            pos_name = pos_tagger.get_pos_tag_ru(token.pos_)
            print(f"  {token.text}: {pos_name} (–ª–µ–º–º–∞: {token.lemma_})")

if __name__ == "__main__":
    test_spacy_directly()
