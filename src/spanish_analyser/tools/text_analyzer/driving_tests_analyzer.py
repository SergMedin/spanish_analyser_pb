#!/usr/bin/env python3
"""
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –±–∏–ª–µ—Ç–æ–≤ –ø–æ –≤–æ–∂–¥–µ–Ω–∏—é

–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç HTML —Ñ–∞–π–ª—ã —Å –±–∏–ª–µ—Ç–∞–º–∏ –∏ —Å–æ–∑–¥–∞—ë—Ç Excel –æ—Ç—á—ë—Ç—ã
"""

import os
import sys
import logging
from pathlib import Path
from datetime import datetime
import time

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º –ø—Ä–æ–µ–∫—Ç–∞
sys.path.append(os.path.join(os.path.dirname(__file__), '../..'))

from spanish_analyser.word_analyzer import WordAnalyzer
from spanish_analyser.config import config
from spanish_analyser.anki_checker import check_anki_before_run
from spanish_analyser.cache import CacheManager  # –ú–µ–Ω–µ–¥–∂–µ—Ä —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø–æ–¥–ø–∞–ø–æ–∫
from spanish_analyser.components.word_comparator import WordComparator
from spanish_analyser.components.anki_connector import AnkiConnector


class DrivingTestsAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –±–∏–ª–µ—Ç–æ–≤ –ø–æ –≤–æ–∂–¥–µ–Ω–∏—é"""
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
        self.word_analyzer = WordAnalyzer()
        
        # –ü–æ–ª—É—á–∞–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
        self.downloads_path = Path(config.get_downloads_folder())
        self.results_path = Path(config.get_results_folder())
        self.max_results_files = config.get_max_results_files()
        self.results_filename_prefix = config.get_results_filename_prefix()
        
        # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self.results_path.mkdir(parents=True, exist_ok=True)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        from spanish_analyser.text_processor import SpanishTextProcessor
        self.text_processor = SpanishTextProcessor()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∞–Ω–∞–ª–∏–∑–∞
        self.analysis_stats = {
            'files_processed': 0,
            'words_found': 0,
            'start_time': datetime.now()
        }
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è –∏–∑ config
        # (–Ω–µ –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º, –µ—Å–ª–∏ —É–∂–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ –≤ CLI)
        config._configure_logging_if_needed()
        self.logger = logging.getLogger(__name__)
        
        self.logger.info("–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        self.logger.info(f"–ü–∞–ø–∫–∞ –∑–∞–≥—Ä—É–∑–æ–∫: {self.downloads_path}")
        self.logger.info(f"–ü–∞–ø–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {self.results_path}")
    
    def connect_to_anki(self) -> bool:
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ AnkiConnect (–±–µ–∑ –ø—Ä—è–º–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞ –∫ –ë–î Anki).
        
        Returns:
            True –µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∫–∞ —É—Å–ø–µ—à–Ω–∞
        """
        try:
            self.logger.info("–ü–æ–¥–∫–ª—é—á–∞—é—Å—å –∫ Anki —á–µ—Ä–µ–∑ AnkiConnect...")
            connector = AnkiConnector()
            if not connector.is_available():
                self.logger.warning("‚ö†Ô∏è AnkiConnect –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü—Ä–æ–¥–æ–ª–∂–∞—é –±–µ–∑ Anki")
                return False

            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—É—é –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å ANKI –≤ WordAnalyzer
            if self.word_analyzer.init_anki_integration():
                self.logger.info("‚úÖ WordAnalyzer –Ω–∞—Å—Ç—Ä–æ–µ–Ω –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å ANKI (AnkiConnect)")
                return True
            else:
                self.logger.warning("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å ANKI")
                return False
        except Exception as e:
            self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Å–ª–æ–≤ –∏–∑ Anki (AnkiConnect): {e}")
            return False
    
    def find_html_files(self, pattern: str = "*.html") -> list:
        """
        –ù–∞—Ö–æ–¥–∏—Ç HTML —Ñ–∞–π–ª—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        
        Args:
            pattern: –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ñ–∞–π–ª–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ HTML —Ñ–∞–π–ª–∞–º
        """
        html_files = list(self.downloads_path.glob(pattern))
        self.logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(html_files)} HTML —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return html_files
    
    def extract_text_from_html(self, html_file: Path) -> str:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ HTML —Ñ–∞–π–ª–∞
        
        Args:
            html_file: –ü—É—Ç—å –∫ HTML —Ñ–∞–π–ª—É
            
        Returns:
            –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        try:
            # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –∏–∑ –∫—ç—à–∞ –ø–æ –ø—É—Ç–∏ –∏ –≤—Ä–µ–º–µ–Ω–∏ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏
            if config.should_cache_html_extraction():
                try:
                    stat = html_file.stat()
                    cache_key = f"html_extract:{str(html_file.resolve())}:{stat.st_mtime}:{stat.st_size}"
                    cache = CacheManager.get_cache()
                    cached = cache.get(cache_key)
                    if cached is not None:
                        self.logger.info(f"üìÑ –ö—ç—à: {html_file.name} ({len(cached)} —Å–∏–º–≤–æ–ª–æ–≤)")
                        return cached
                except Exception:
                    pass
            with open(html_file, 'r', encoding='utf-8') as f:
                html_content = f.read()
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–π –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
            cleaned_text = self._extract_text_improved(html_content)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ–º –∏—Å–ø–∞–Ω—Å–∫–∏–µ —Å–ª–æ–≤–∞ –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞
            spanish_words = self.text_processor.extract_spanish_words(cleaned_text)
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            final_text = ' '.join(spanish_words)
            
            self.logger.debug(f"–ò–∑–≤–ª–µ—á—ë–Ω —Ç–µ–∫—Å—Ç –∏–∑ {html_file.name}: {len(final_text)} —Å–∏–º–≤–æ–ª–æ–≤, {len(spanish_words)} —Å–ª–æ–≤")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
            if config.should_cache_html_extraction():
                try:
                    cache.set(cache_key, final_text)
                    self.logger.debug(f"üíæ –¢–µ–∫—Å—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω: {html_file.name}")
                except Exception:
                    pass
            return final_text
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞ –∏–∑ {html_file.name}: {e}")
            return ""
    
    def _extract_text_improved(self, html_content: str) -> str:
        """
        –£–ª—É—á—à–µ–Ω–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ HTML —Å –ø–æ–∏—Å–∫–æ–º –±–ª–æ–∫–æ–≤ col-md-8
        
        Args:
            html_content: HTML —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
            
        Returns:
            –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        try:
            from bs4 import BeautifulSoup
            
            # –°–æ–∑–¥–∞—ë–º –æ–±—ä–µ–∫—Ç BeautifulSoup
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤—Å–µ –±–ª–æ–∫–∏ —Å –∫–ª–∞—Å—Å–æ–º "col-md-8" (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –∫–æ–¥–µ)
            blocks = soup.find_all('div', class_='col-md-8')
            
            if blocks:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –∫–∞–∂–¥–æ–≥–æ –±–ª–æ–∫–∞ –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ–º –∏—Ö
                block_texts = []
                for block in blocks:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π –∏ –Ω–∞–¥—ë–∂–Ω—ã–π –º–µ—Ç–æ–¥ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
                    block_text = block.get_text(separator=" ", strip=True)
                    if block_text and len(block_text) > 10:  # –ò—Å–∫–ª—é—á–∞–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –±–ª–æ–∫–∏
                        block_texts.append(block_text)
                
                text = "\n".join(block_texts)
                self.logger.debug(f"–ù–∞–π–¥–µ–Ω–æ {len(blocks)} –±–ª–æ–∫–æ–≤ col-md-8")
            else:
                raise RuntimeError("–ù–µ –Ω–∞–π–¥–µ–Ω –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç (col-md-8) –≤ HTML. –û–ø–µ—Ä–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –Ω—É–∂–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã.")
            
            return text.strip()
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —É–ª—É—á—à–µ–Ω–Ω–æ–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞: {e}")
            raise
    
    def _extract_text_from_element(self, element) -> str:
        """
        –ù–∞–¥—ë–∂–Ω–æ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ HTML —ç–ª–µ–º–µ–Ω—Ç–∞
        
        Args:
            element: HTML —ç–ª–µ–º–µ–Ω—Ç BeautifulSoup
            
        Returns:
            –ò–∑–≤–ª–µ—á—ë–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
        """
        try:
            # –ú–µ—Ç–æ–¥ 1: –ü—Ä—è–º–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
            text = element.get_text(separator=" ", strip=True)
            
            # –ú–µ—Ç–æ–¥ 2: –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π, –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –ø–æ —á–∞—Å—Ç—è–º
            if len(text) < 10:  # –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –∏–∑ –≤—Å–µ—Ö –¥–æ—á–µ—Ä–Ω–∏—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
                child_texts = []
                for child in element.children:
                    if hasattr(child, 'get_text'):
                        child_text = child.get_text(strip=True)
                        if child_text:
                            child_texts.append(child_text)
                    elif hasattr(child, 'string') and child.string:
                        child_text = child.string.strip()
                        if child_text:
                            child_texts.append(child_text)
                
                if child_texts:
                    text = " ".join(child_texts)
            
            # –ú–µ—Ç–æ–¥ 3: –ï—Å–ª–∏ –≤—Å—ë –µ—â—ë –∫–æ—Ä–æ—Ç–∫–∏–π, –ø—Ä–æ–±—É–µ–º –∏–∑–≤–ª–µ—á—å –∞—Ç—Ä–∏–±—É—Ç—ã
            if len(text) < 10:
                # –ò—â–µ–º —Ç–µ–∫—Å—Ç –≤ –∞—Ç—Ä–∏–±—É—Ç–∞—Ö
                for attr_name, attr_value in element.attrs.items():
                    if isinstance(attr_value, str) and len(attr_value) > len(text):
                        text = attr_value
            
            return text.strip()
            
        except Exception as e:
            self.logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–∞: {e}")
            return ""
    
    def analyze_html_files(self, html_files: list = None) -> dict:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç HTML —Ñ–∞–π–ª—ã –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å–ª–æ–≤–∞
        
        Args:
            html_files: –°–ø–∏—Å–æ–∫ HTML —Ñ–∞–π–ª–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            –°–ª–æ–≤–∞—Ä—å —Å–æ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–æ–π –∞–Ω–∞–ª–∏–∑–∞
        """
        if html_files is None:
            html_files = self.find_html_files()
        
        self.logger.info(f"–ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ {len(html_files)} HTML —Ñ–∞–π–ª–æ–≤")
        
        total_words = 0
        
        for html_file in html_files:
            try:
                t_file_start = time.time()
                self.logger.debug(f"‚û°Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞: {html_file.name}")
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç
                text = self.extract_text_from_html(html_file)
                if text:
                    self.logger.debug(f"‚û°Ô∏è spaCy-–∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ {html_file.name}: {len(text)} —Å–∏–º–≤–æ–ª–æ–≤")
                    # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª–æ–≤–∞ –≤ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
                    self.word_analyzer.add_words_from_text(text)
                    
                    # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Å–ª–æ–≤–∞ –≤ —ç—Ç–æ–º —Ñ–∞–π–ª–µ
                    words_in_file = len(text.split())
                    total_words += words_in_file
                    
                    self.analysis_stats['files_processed'] += 1
                    self.logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω {html_file.name}: –Ω–∞–π–¥–µ–Ω–æ {words_in_file} —Å–ª–æ–≤ (dt={time.time()-t_file_start:.2f}s)")
                else:
                    self.logger.warning(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω {html_file.name}: –ø—É—Å—Ç–æ–π —Ç–µ–∫—Å—Ç")
                    
            except Exception as e:
                self.logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ {html_file.name}: {e}")
        
        self.analysis_stats['words_found'] = total_words
        
        self.logger.info(f"–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω. –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {self.analysis_stats['files_processed']}")
        self.logger.info(f"–í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ —Å–ª–æ–≤: {total_words}")
        
        return {
            'files_processed': self.analysis_stats['files_processed'],
            'words_found': total_words,
            'unique_words': len(self.word_analyzer.word_frequencies)
        }
    
    def generate_filename_with_timestamp(self, prefix: str = "driving_tests_analysis") -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–º—è —Ñ–∞–π–ª–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π
        
        Args:
            prefix: –ü—Ä–µ—Ñ–∏–∫—Å –¥–ª—è –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞
            
        Returns:
            –ò–º—è —Ñ–∞–π–ª–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        return f"{prefix}_{timestamp}.xlsx"
    
    def cleanup_old_files(self):
        """–£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –æ—Å—Ç–∞–≤–ª—è—è –Ω–µ –±–æ–ª–µ–µ max_files"""
        try:
            # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ Excel —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            excel_files = list(self.results_path.glob("*.xlsx"))
            
            if len(excel_files) > self.max_results_files:
                # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –∏–∑–º–µ–Ω–µ–Ω–∏—è (—Å—Ç–∞—Ä—ã–µ –ø–µ—Ä–≤—ã–º–∏)
                excel_files.sort(key=lambda x: x.stat().st_mtime)
                
                # –£–¥–∞–ª—è–µ–º —Å–∞–º—ã–µ —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã
                files_to_delete = excel_files[:-self.max_results_files]
                
                for old_file in files_to_delete:
                    old_file.unlink()
                    self.logger.info(f"–£–¥–∞–ª—ë–Ω —Å—Ç–∞—Ä—ã–π —Ñ–∞–π–ª: {old_file.name}")
                
                self.logger.info(f"–£–¥–∞–ª–µ–Ω–æ {len(files_to_delete)} —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤")
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤: {e}")
    
    def export_results(self, include_categories: bool = True) -> str:
        """
        –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –≤ Excel
        
        Args:
            include_categories: –í–∫–ª—é—á–∞—Ç—å –ª–∏ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ —á–∞—Å—Ç–æ—Ç–µ
            
        Returns:
            –ü—É—Ç—å –∫ —Å–æ–∑–¥–∞–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
        """
        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π
            filename = self.generate_filename_with_timestamp("driving_tests_analysis")
            file_path = self.results_path / filename
            
            # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            self.word_analyzer.export_to_excel(str(file_path), include_categories)
            
            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã
            self.cleanup_old_files()
            
            self.logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤: {filename}")
            return str(file_path)
            
        except Exception as e:
            self.logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —ç–∫—Å–ø–æ—Ä—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤: {e}")
            return ""
    
    
    def reset_analysis(self):
        """–°–±—Ä–∞—Å—ã–≤–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞"""
        self.word_analyzer.reset()
        self.analysis_stats = {
            'files_processed': 0,
            'words_found': 0,
            'start_time': datetime.now()
        }
        self.logger.info("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Å–±—Ä–æ—à–µ–Ω—ã")
    
    def close(self):
        """–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ (—Å–æ–µ–¥–∏–Ω–µ–Ω–∏–π —Å Anki –Ω–µ—Ç)."""
        pass


def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    print("üìä –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –±–∏–ª–µ—Ç–æ–≤ –ø–æ –≤–æ–∂–¥–µ–Ω–∏—é\n")
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ AnkiConnect (–Ω–µ —Ç—Ä–µ–±—É–µ–º –∑–∞–∫—Ä—ã–≤–∞—Ç—å Anki)
    print("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ AnkiConnect...")
    try:
        _conn = AnkiConnector()
        if _conn.is_available():
            decks = _conn.find_spanish_decks("Spanish")
            print(f"‚úÖ AnkiConnect –¥–æ—Å—Ç—É–ø–µ–Ω. –ò—Å–ø–∞–Ω—Å–∫–∏—Ö –∫–æ–ª–æ–¥: {len(decks)}")
        else:
            print("‚ö†Ô∏è AnkiConnect –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ë—É–¥–µ–º —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ Anki")
    except Exception:
        print("‚ö†Ô∏è AnkiConnect –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ë—É–¥–µ–º —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ Anki")
    
    # –°–æ–∑–¥–∞—ë–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
    analyzer = DrivingTestsAnalyzer()
    
    try:
        # –ü–æ–¥–∫–ª—é—á–∞–µ–º—Å—è –∫ Anki
        print("üîó –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Anki...")
        if not analyzer.connect_to_anki():
            print("‚ö†Ô∏è –ü—Ä–æ–¥–æ–ª–∂–∞—é –±–µ–∑ Anki...")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º HTML —Ñ–∞–π–ª—ã
        print("\nüìÑ –ù–∞—á–∏–Ω–∞—é –∞–Ω–∞–ª–∏–∑ HTML —Ñ–∞–π–ª–æ–≤...")
        analysis_result = analyzer.analyze_html_files()
        
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:")
        print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Ñ–∞–π–ª–æ–≤: {analysis_result['files_processed']}")
        print(f"   –ù–∞–π–¥–µ–Ω–æ —Å–ª–æ–≤: {analysis_result['words_found']}")
        print(f"   –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {analysis_result['unique_words']}")
        
        # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        print(f"\nüìÅ –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É—é —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã...")
        export_file = analyzer.export_results()
        
        if export_file:
            print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —ç–∫—Å–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –≤: {export_file}")
        
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–∞
        try:
            from spanish_analyser.cache import CacheManager  # –ú–µ–Ω–µ–¥–∂–µ—Ä —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø–æ–¥–ø–∞–ø–æ–∫
            cache = CacheManager.get_cache()
            cache_stats = cache.stats_dict()
            if cache_stats['hits'] > 0 or cache_stats['stores'] > 0:
                print(f"\nüíæ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫—ç—à–∞:")
                print(f"   –ü–æ–ø–∞–¥–∞–Ω–∏–π: {cache_stats['hits']}")
                print(f"   –ü—Ä–æ–º–∞—Ö–æ–≤: {cache_stats['misses']}")
                print(f"   –§–∞–π–ª–æ–≤ –≤ –∫—ç—à–µ: {cache_stats['files']}")
                print(f"   –†–∞–∑–º–µ—Ä –∫—ç—à–∞: {cache_stats['size_mb']:.1f} –ú–ë")
        except Exception:
            pass
        
    except Exception as e:
        print(f"\n‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {e}")
        return 1
    finally:
        analyzer.close()
    
    return 0


if __name__ == "__main__":
    exit(main())
